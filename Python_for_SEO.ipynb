{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM3enJ3gMWAxT7D8DYvy6Gt",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrilio/seo/blob/main/Python_for_SEO.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Google Auto Complete"
      ],
      "metadata": {
        "id": "Fz1V5TYi347a"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install --upgrade ecommercetools\n",
        "from ecommercetools import seo\n",
        "import csv\n",
        "import pandas as pd\n",
        "suggestions = seo.google_autocomplete(\"cara membuat\", include_expanded=True)\n",
        "print(suggestions)\n",
        "df = pd.DataFrame(suggestions)\n",
        "headerList = ['Term', 'Relevance']\n",
        "df.to_csv('file_name.csv',header=headerList,index=False)"
      ],
      "metadata": {
        "id": "IaGHVREE3y7J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sitemap Status Code Checker"
      ],
      "metadata": {
        "id": "FslSA7Wh3-jL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#!pip3 install --upgrade ecommercetools\n",
        "import requests\n",
        "import pandas as pd\n",
        "from ecommercetools import seo\n",
        "df = seo.get_sitemap('https://www.traveloka.com/sitemap/hotel_detail.xml')\n",
        "urls = df['loc'].tolist()\n",
        "df_output = pd.DataFrame(columns=['original_url', 'original_status', 'destination_url', 'destination_status'])\n",
        "for url in urls:\n",
        "\n",
        "    response = requests.get(url, headers={'User-Agent': 'Google Chrome'})\n",
        "    row = {}\n",
        "\n",
        "    if response.history:\n",
        "        for step in response.history:\n",
        "            row['original_url'] = step.url\n",
        "            row['original_status'] = step.status_code\n",
        "        row['destination_url'] = response.url\n",
        "        row['destination_status'] = response.status_code\n",
        "    else:\n",
        "        row['original_url'] = response.url\n",
        "        row['original_status'] = response.status_code\n",
        "        row['destination_url'] = ''\n",
        "        row['destination_status'] = ''\n",
        "\n",
        "    print(row)\n",
        "\n",
        "    df_output = df_output.append(row, ignore_index=True)\n",
        "df_output.to_csv('file_name1.csv', header=True, index=False)\n",
        "df_output"
      ],
      "metadata": {
        "id": "0eMKGU8q4AuQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "URL Status Code Checker in txt"
      ],
      "metadata": {
        "id": "Y7J2vUB64DLU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "def get_status_code(url):\n",
        "    try:\n",
        "        r = requests.get(url)\n",
        "        print (\"Processing \" + url)\n",
        "        if len(r.history) > 0:\n",
        "            chain = \"\"\n",
        "            code = r.history[0].status_code\n",
        "            final_url = r.url\n",
        "            for resp in r.history:\n",
        "                chain += resp.url + \" | \"\n",
        "            return str(code) + '\\t' + str(len(r.history)) + '\\t' + chain + '\\t' + final_url + '\\t'\n",
        "        else:\n",
        "            return str(r.status_code) + '\\t\\t\\t\\t'\n",
        "    except requests.ConnectionError:\n",
        "        print(\"Error: failed to connect.\")\n",
        "        return '0\\t\\t\\t\\t'\n",
        "input_file = 'url.txt'\n",
        "output_file = 'output.txt'\n",
        "with open(output_file, 'w') as o_file:\n",
        "    o_file.write('URL\\tStatus\\tNumber of redirects\\tRedirect Chain\\tFinal URL\\t\\n')\n",
        "    f = open(input_file, \"r\")\n",
        "    lines = f.read().splitlines()\n",
        "    for line in lines:\n",
        "        code = get_status_code(line)\n",
        "        o_file.write(line + \"\\t\" + str(code) + \"\\t\\n\")\n",
        "    f.close()"
      ],
      "metadata": {
        "id": "A7HpNVnw4E6a"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "GMB collection"
      ],
      "metadata": {
        "id": "vRVuXxaR4NX8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import requests\n",
        "import json\n",
        "import csv\n",
        "import time\n",
        "\n",
        "# Set up the API key and search query\n",
        "api_key = '' #maps api key\n",
        "query = 'bengkel+di+bogor'\n",
        "# Set up the URL to send a request to the Google Maps API\n",
        "url = f'https://maps.googleapis.com/maps/api/place/textsearch/json?query={query}&key={api_key}&radius=1000'\n",
        "results = []\n",
        "next_page_token = None\n",
        "# Loop through pages of results until we've reached the desired number or there are no more pages\n",
        "while len(results) < 100 and (next_page_token is None or len(results) % 20 == 0):\n",
        "    # If we have a next_page_token, add it to the URL\n",
        "    if next_page_token is not None:\n",
        "        url = f'https://maps.googleapis.com/maps/api/place/textsearch/json?pagetoken={next_page_token}&key={api_key}'\n",
        "    # Send a request to the Google Maps API and retrieve the JSON response\n",
        "    response = requests.get(url)\n",
        "    json_response = json.loads(response.content)\n",
        "    # Extract the information you need from the JSON response\n",
        "    new_results = json_response['results']\n",
        "    results.extend(new_results)\n",
        "    # If there's a next page token, set it so we can retrieve the next page of results\n",
        "    next_page_token = json_response.get('next_page_token')\n",
        "    # Wait for a short time before making the next request to avoid hitting the API rate limit\n",
        "    time.sleep(2)\n",
        "# Remove duplicates from the results\n",
        "results = list({r['place_id']: r for r in results}.values())\n",
        "# Sort the results by rating and total ratings\n",
        "results = sorted(results, key=lambda x: (-x['rating'], -x['user_ratings_total']))[:100]\n",
        "# Set up the CSV file and write the header row\n",
        "with open('bengkel_bogor.csv', mode='w', newline='', encoding='utf-8') as file:\n",
        "    writer = csv.writer(file)\n",
        "    writer.writerow(['Name', 'Address', 'Rating', 'Total Ratings', 'Phone Number', 'Website', 'Google Maps URL'])\n",
        "    # Write each restaurant's information to the CSV file\n",
        "    for result in results:\n",
        "        name = result['name']\n",
        "        address = result['formatted_address']\n",
        "        rating = result.get('rating', '')\n",
        "        total_ratings = result.get('user_ratings_total', '')\n",
        "        place_id = result['place_id']\n",
        "        google_maps_url = f'https://www.google.com/maps/place/?q=place_id:{place_id}'\n",
        "        # Get the phone number and website for the place\n",
        "        details_url = f'https://maps.googleapis.com/maps/api/place/details/json?place_id={place_id}&key={api_key}'\n",
        "        details_response = requests.get(details_url)\n",
        "        details_json = json.loads(details_response.content)\n",
        "        phone_number = details_json['result'].get('formatted_phone_number', '')\n",
        "        website = details_json['result'].get('website', '')\n",
        "        writer.writerow([name, address, rating, total_ratings, phone_number, website, google_maps_url])\n",
        "    while next_page_token:\n",
        "        next_url = f'https://maps.googleapis.com/maps/api/place/textsearch/json?pagetoken={next_page_token}&key={api_key}'\n",
        "        next_response = requests.get(next_url)\n",
        "        next_json_response = json.loads(next_response.content)\n",
        "        next_results = next_json_response['results']\n",
        "        next_page_token = next_json_response.get('next_page_token', None)\n",
        "        for result in next_results:\n",
        "            name = result['name']\n",
        "            address = result['formatted_address']\n",
        "            rating = result.get('rating', '')"
      ],
      "metadata": {
        "id": "G-R9xTg64GrU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}